Este estudo objetivou avaliar a eficácia da aprendizagem métrica na identificação de viés ideológico, integrando modelos pré-treinados e 
funções de perda contrastivas. Os resultados demonstram que a \textit{Contrastive Loss} otimiza a separação vetorial, superando o baseline de 
\cite{baly2020we} em $12$ pontos percentuais no cenário \textit{media-bias split}. A arquitetura mostrou-se competitiva frente a LLMs em modo \textit{zero-shot}, 
validando a viabilidade de modelos leves e eficientes para a análise de nuances discursivas.

Para trabalhos futuros, pretende-se explorar técnicas de \textit{Domain Adaptation} para otimizar a transferência de conhecimento e elevar o desempenho em 
dados de fontes não expostas durante o treinamento. Além disso, planeja-se investigar o comportamento de LLMs sob estratégias de \textit{Few-Shot} e \textit{Fine-Tuning}, permitindo 
uma comparação mais consistente com a arquitetura proposta. Tais avanços visam mitigar a memorização de padrões específicos de veículos e consolidar a robustez do modelo em 
cenários de generalização rigorosa.