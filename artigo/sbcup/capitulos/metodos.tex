A metodologia assume que o viés ideológico se manifesta em padrões discursivos, processando textos via modelos pré-treinados e 
otimizando \textit{embeddings} por \textit{Contrastive} e \textit{Triplet Loss}. Conforme a Figura~\ref{fig:fluxo_dados}, o 
fluxo abrange quatro etapas: definição dos conjuntos de dados, geração de representações por aprendizagem métrica, 
treinamento de classificadores e análise de desempenho. As seções seguintes detalham cada módulo da arquitetura proposta.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/fig_abordagem_proposta_texto.pdf}
\caption{\centering Visão geral do método de detecção de viés ideológico por meio do conteúdo textual de artigos de notícias.}
\label{fig:fluxo_dados}
\end{figure}

\subsection{Dados Experimentais}\label{sec:dados}
Para o desenvolvimento deste estudo, utilizou-se o conjunto de dados \textit{Article Bias Prediction} (ABP) \cite{baly2020we}, composto
por $30.246$ notícias em inglês rotuladas em três categorias (\textit{left, center} e \textit{right}.) A fidedignidade dos rótulos
advém plataforma AllSides\footnote{\url{https://www.allsides.com/media-bias/media-bias-rating-methods}}, que
emprega auditorias rigorosas e revisões da comunidade, conforme ilustrado na Figura~\ref{fig:example_article}. Visando a integridade
da análise, o \textit{corpus} foi pré-processado para remover marcadores de autoria e portais, garantindo que o modelo identifique nuances
linguísticas em vez de apenas a fonte da notícia.


\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/example_areticle.png}
\caption{\centering Exemplo de uma amostra de artigo de notícia com o tópico sobre a pandemia de coronavírus \cite{baly2020we}.}
\label{fig:example_article}
\end{figure}

A robustez metodológica foi validada por dois critérios de particionamento: o \textit{media-bias split} (Tabela~\ref{tab:particoes_media}), que 
segrega veículos para mitigar o vazamento de dados, e o \textit{random split} (Tabela~\ref{tab:particoes_random}), que mantém a consistência 
na distribuição de classes entre treino e validação. Adicionalmente, a generalização foi avaliada com o conjunto \textit{FlipBias} \cite{chen2018learning}, 
contendo $2.781$ eventos sob múltiplas perspectivas. Os modelos seguiram as diretrizes de \cite{lin2024indivecexplorationleveraginglarge,lin-etal-2025-investigating} 
para aferir a robustez das representações em dados não expostos no treinamento.

\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{media-bias split}.} \label{tab:particoes_media}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline 
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left   & 8.861  & 33,32\% & Left   & 1.640 & 69,60\% & Left   & 402 & 30,92\% \\
        Center & 7.488  & 28,16\% & Center & 618   & 26,23\% & Center & 299 & 23,00\% \\
        Right  & 10.241 & 38,51\% & Right  & 98    & 4,15\%  & Right  & 599 & 46,07\% \\ 
        \hline
    \end{tabularx}
\end{table*}

\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{random split}.} \label{tab:particoes_random}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left & 9.750  & 34,84\% & Left & 2.438 & 34,84\% & Left & 402 & 30,92\% \\
        Center   & 7.988  & 28,55\% & Center   & 1.998 & 28,55\% & Center   & 299 & 23,00\% \\ 
        Right  & 10.240 & 36,60\% & Right  & 2.560 & 36,59\% & Right  & 599 & 46,07\% \\
        \hline
    \end{tabularx}
\end{table*}

\subsection{Tarefa de Geração de \textit{Embeddings}}\label{sec:representacoes}

Para a execução da tarefa, a Figura~\ref{fig:fluxo_embeddings} ilustra o fluxo de processamento adotado. O processo inicia-se com a
\textit{tokenização} dos artigos de notícias, seguida pela mineração de exemplos. Esta etapa é fundamental para selecionar amostras
informativas que otimizam a convergência e o aprendizado do modelo.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{./imagens/fig_geracao_embeddings.pdf}
    \caption{\centering Fluxo de treinamento e geração de características para artigos de notícias.}
    \label{fig:fluxo_embeddings}
\end{figure}

Conforme delineado na arquitetura apresentada, empregaram-se dois modelos fundamentados em \textit{Bidirectional Encoder Representations from Transformers (BERT)} \cite{bert}, 
reconhecidos pela eficácia na modelagem de dependências de longo alcance e na extração de relações semânticas granulares \cite{Zhang}. 
A seleção recaiu sobre o DistilBERT \cite{distilbert} e o DistilRoBERTa \cite{roberta}, variantes destiladas que preservam a robustez das arquiteturas originais, 
contudo, apresentam reduções substanciais no custo computacional e nos requisitos de memória.

O modelo \textit{Transformer} processa as sequências de entrada, seguido por uma camada de \textit{Mean Pooling} que consolida 
as representações em um vetor único. O (\textit{fine-tuning}) é regido por estratégias de aprendizagem métrica\footnote{Aprendizagem métrica (ou \textit{metric learning}) refere-se ao uso de algoritmos para aprender uma função de distância que capture a similaridade entre dados.}, 
utilizando as funções de perda \textit{Contrastive Loss} ou \textit{Triplet Loss}. Tal abordagem assegura que os \textit{embeddings} gerados na saída 
posicionem instâncias contextualmente similares em regiões próximas do espaço de representação, otimizando a discriminação entre as classes.

No que se refere ao pré-processamento, as \textit{stopwords} foram preservadas, visto que a arquitetura BERT demonstra eficácia na extração de nuances contextuais 
a partir desses elementos. Por fim, o treinamento foi estabelecido com um limite de $100$ épocas, utilizando o otimizador Adam com 
taxa de aprendizado de $0,0001$ e \textit{batch size} de $16$. Para mitigar o \textit{overfitting} e assegurar a capacidade de 
generalização dos modelos, aplicou-se a técnica de \textit{Early Stopping} com paciência de $30$ ciclos, monitorando-se a 
convergência da função de perda no conjunto de validação.

\subsubsection{Mecanismos de Aproximação e Distanciamento}\label{sec:funcoes}


Nesta abordagem, os codificadores (DistilBERT e DistilRoBERTa) ajustam os pesos de suas camadas para otimizar a 
qualidade dos \textit{embeddings} via \textit{Contrastive Loss} e \textit{Triplet Loss}. 
O objetivo é o aprendizado de representações vetoriais onde instâncias semanticamente similares convirjam no espaço representação, 
enquanto exemplos dissimilaridades sejam repelidos.

A \textit{Contrastive Loss} é aplicada utilizando a distância Euclidiana sobre pares de exemplos, conforme definido na Equação 1:

\begin{equation}
L = \frac{1}{2} (1-y) D^2 + \frac{1}{2} y \{ \max(0, m - D) \}^2
\end{equation}

Onde $y$ representa o rótulo binário (0 para similar, 1 para dissimilar), $D$ denota a distância entre as representações e $m$ é a margem de separação. 

Complementarmente, a \textit{Triplet Loss} utiliza triplas compostas por uma âncora ($a$), um exemplo positivo ($p$) e um negativo ($n$). 
O objetivo, expresso na Equação 2, assegura que a distância entre a âncora e o positivo seja inferior à distância entre a âncora e o negativo por uma margem $m$:

\begin{equation}
L = \max(0, D(a, p) - D(a, n) + m)
\end{equation}

Para otimizar o aprendizado, empregou-se o \textit{mining} de negativos \textit{semi-hard}. Esses exemplos, 
que satisfazem a condição $D(a, p) < D(a, n) + m$, fornecem gradientes mais informativos e 
mitigam o \textit{overfitting} em comparação a negativos \textit{hard} \cite{loss}. Esse processo 
refina a capacidade discriminatória do modelo, permitindo que os \textit{embeddings} 
capturem relações semânticas profundas, como a ideologia de uma notícia, independentemente da fonte de publicação.

\subsection{Tarefa de Classificação: Modelos e Parametrizaçao}\label{sec:classificacao}
Após o mapeamento dos \textit{embeddings}, onde a proximidade entre os veotres reflete a similaridade ideológica das notícias.
A classificação dos artigos foi realizada por meio de três algoritmos: \textit{K-Nearest Neighbors (KNN)}, \textit{K-Means} e
\textit{Multilayer Perceptron (MLP)}. O \textit{KNN} e o \textit{K-Means} foram utilizados para explorar a organização dos dados
por vizinhaça e agrupamento, respectivamente. Para o \textit{KNN}, aplicou-se um \textit{grid search} sistemático para otimização de hiperparâmetros, variando o número de vizinhos ($k$)
entre $5, 10, 15, 20, 25$ e $30$. Já o \textit{K-Means} foi configurado com o número de \textit{clusters} equivalente às classes
presentes no conjunto de dados ABP.

A rede \textit{MLP} foi estruturada com duas camadas densas (512 e 256 neurônios). Adotou-se a função de ativação \textit{ReLU}
para garantir um treinamento mais rápido e estável \cite{Zhang}, enquanto a camada de saída utilizou a \textit{softmax} para a 
classificação final. O modelo otimizado com o algoritmo \textit{Adam} e a função de perda
\textit{Categorical Cross-Entropy}, escolhas consolidadas na literatura para problemas multiclasse \cite{goodfellow2016deep}.

A confiabilidade do experimento foi assegurada pela validação cruzada estritificada (5-fold). Esse procedimento garante que a proporção das classes
seja mantida em todas as etapas, evitando resultados enviesados e permitindo medir com precisão a capacidade do modelo em classificar novos dados \cite{brink2016real}.

\subsection{Avaliação de Desempenho}

O desempenho dos modelos de classificação será avaliado pelas métricas de Acurácia e \textit{Macro F1-score}.
A Acurácia (Equação~\ref{eq:accuracy}) fornece uma medida geral da taxa de acerto para o conjunto de classes $C$.
Complementarmente, o \textit{Macro F1-score} (Equação~\ref{eq:macrof1}) permite uma avaliação equilibrada entre as
classes, mitigando distorções causadas por eventuais desbalanceamento no conjunto de dados.

As métricas são formalmente definidas conforme segue:

%\begin{equation}\label{eq:accuracy}
%\text{Acurácia} = \frac{1}{|C|} \sum_{c \in C} \left ( \frac{TP_c + TN_c}{TP_c + TN_c + FP_c + FN_c} \right )
%\end{equation}

%\begin{equation}\label{eq:macrof1}
%\text{Macro } F1 = \frac{1}{C} \sum_{c \in C} F1_c
%\end{equation}

\noindent
\begin{minipage}{0.50\linewidth}
\begin{equation}\label{eq:accuracy}
\text{Acurácia} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
\end{minipage}\hfill
\begin{minipage}{0.48\linewidth}
\begin{equation}\label{eq:macrof1}
\text{Macro } F1 = \frac{1}{|C|} \sum_{c \in C} F1_c
\end{equation}
\end{minipage}

Em que $F1_c$ representa a média harmônica entre a Precisão ($P_c$) e a Revocação ($R_c$) para cada classe:

%\begin{equation}\label{eq:prec_rec} 
%  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c} 
%\end{equation}

%\begin{equation}\label{eq:f1_calc} 
%  F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
%\end{equation}

\
\begin{equation}\label{eq:prec_rec} 
  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c}, \quad F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
\end{equation}

Neste contexto, $TP$, $TN$, $FP$ e $FN$ representam, respectivamente, os verdadeiros positivos, 
verdadeiros negativos, falsos positivos e falsos negativos. 

A validação da hipótese de pesquisa --- de que o discurso textual reflete o viés ideológico --- dar-se-á 
mediante a obtenção de altos índices em ambas as métricas. 
Espera-se que valores elevados de \textit{Macro F1-score} confirmem a capacidade discriminatória do modelo entre
as diferentes vertentes ideológicas, assegurando que o desempenho não seja reflexo de uma classe majoritária no conjunto de dados.

%\subsection{Configuração dos Experimentos e Espaço de Busca}

%A exploração da configuração ótima para os modelos foi formalizada por uma função de desempenho $\mathcal{P}$, que parametriza 
%as variações arquiteturais do método proposto conforme a Equação~\ref{eq:funcao_experimento}. Nesta formulação, $S$ 
%representa o protocolo de particionamento dos dados (\textit{media-bias} ou \textit{random split}), $R$ define o codificador 
%empregado na geração dos \textit{embeddings}, $L$ denota a função de perda aplicada ao aprendizado de representação em $R$, e $C$ 
%designa o algoritmo de classificação final.

%\begin{equation}\label{eq:funcao_experimento} 
%  \mathcal{P} = f(S, R, L, C) 
%\end{equation}

%O objetivo experimental consiste em identificar a tupla de parâmetros $\hat{e}$ que maximize o desempenho global do método proposto. 
%Tal busca é definida matematicamente pela operação de \textit{argmax} apresentada na Equação~\ref{eq:argmax}, permitindo a 
%identificação sistemática da arquitetura que apresenta os melhores índices de acurácia e \textit{Macro F1-score} entre todas as 
%combinações testadas.

%\begin{equation}\label{eq:argmax} 
%  \hat{e} = \arg\max f(S, R, L, C) 
%\end{equation}

\subsection{Ambiente de Execução}

A linguagem Python, com as bibliotecas NumPy, Pandas, Scikit-Learn e PyTorch, foi a ferramenta primária para implementação e avaliação dos modelos. 
Os experimentos ocorreram em um servidor equipado com processador Intel Xeon W-2235, $128$ GB de RAM e GPU NVIDIA RTX $8000$ ($48$ GB VRAM), 
visando a aceleração em hardware. %Comprometendo-se com a transparência e a reprodutibilidade técnica, o código-fonte, 
%hiperparâmetros e \textit{scripts} de pré-processamento estão publicamente disponíveis\footnote{\url{https://github.com/jailsonpj/detecting-ideological-bias}}.