@inproceedings{baly2020we,
  author      = {Baly, Ramy and Da San Martino, Giovanni and Glass, James and Nakov, Preslav},
  title       = {We Can Detect Your Bias: Predicting the Political Ideology of News Articles},
  booktitle   = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year        = {2020},
  pages       = {4982--4991},
  NOpublisher = {Association for Computational Linguistics},
}

@article{bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{distilbert,
  title={DistilBERT, A Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter},
  author={Sanh, V},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}
@inproceedings{Zhang,
  title={Deep neural networks with pre-train model BERT for aspect-level sentiments classification},
  author={Zhang, Yunxiang and Rao, Zhuyi},
  booktitle={2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)},
  pages={923--927},
  year={2020},
  organization={IEEE}
}

@misc{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian},
  year={2016},
  publisher={MIT press}
}

@article{nti2021performance,
  title={Performance of machine learning algorithms with different K values in K-fold cross-validation},
  author={Nti, Isaac Kofi and Nyarko-Boateng, Owusu and Aning, Justice and others},
  journal={International Journal of Information Technology and Computer Science},
  volume={13},
  number={6},
  pages={61--71},
  year={2021},
  publisher={MECS Publisher}
}

@inproceedings{loss,
  author={Kertész, Gábor},
  booktitle={2021 IEEE 19th World Symposium on Applied Machine Intelligence and Informatics (SAMI)}, 
  title={Different triplet sampling techniques for lossless triplet loss on metric similarity learning}, 
  year={2021},
  pages={000449-000454},
  doi={10.1109/SAMI50585.2021.9378628}}

@article{brink2016real,
  title={Real-World Machine Learning. Manning Publications},
  author={Brink, H and Richards, J and Fetherolf, M},
  year={2016}
}

@inproceedings{lin-etal-2025-investigating,
    title = "Investigating Bias in {LLM}-Based Bias Detection: Disparities between {LLM}s and Human Perception",
    author = "Lin, Luyang  and
      Wang, Lingzhi  and
      Guo, Jinsong  and
      Wong, Kam-Fai",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.709/",
    pages = "10634--10649",
    abstract = "The pervasive spread of misinformation and disinformation in social media underscores the critical importance of detecting media bias. While robust Large Language Models (LLMs) have emerged as foundational tools for bias prediction, concerns about inherent biases within these models persist. In this work, we investigate the presence and nature of bias within LLMs and its consequential impact on media bias detection. Departing from conventional approaches that focus solely on bias detection in media content, we delve into biases within the LLM systems themselves. Through meticulous examination, we probe whether LLMs exhibit biases, particularly in political bias prediction and text continuation tasks. Additionally, we explore bias across diverse topics, aiming to uncover nuanced variations in bias expression within the LLM framework. Importantly, we propose debiasing strategies, including prompt engineering and model fine-tuning. Extensive analysis of bias tendencies across different LLMs sheds light on the broader landscape of bias propagation in language models. This study advances our understanding of LLM bias, offering critical insights into its implications for bias detection tasks and paving the way for more robust and equitable AI systems"
}

@inproceedings{chen2018learning,
  title={Learning to flip the bias of news headlines},
  author={Chen, Wei-Fan and Wachsmuth, Henning and Al Khatib, Khalid and Stein, Benno},
  booktitle={Proceedings of the 11th International conference on natural language generation},
  pages={79--88},
  year={2018}
}

@misc{lin2024indivecexplorationleveraginglarge,
    title={IndiVec: An Exploration of Leveraging Large Language Models for Media Bias Detection with Fine-Grained Bias Indicators}, 
    author={Luyang Lin and Lingzhi Wang and Xiaoyan Zhao and Jing Li and Kam-Fai Wong},
    year={2024},
    eprint={2402.00345},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2402.00345}, 
}