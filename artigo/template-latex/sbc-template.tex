\documentclass[12pt]{article}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{array} % Necessário para o >{\centering\arraybackslash}
\usepackage{amsmath}
\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}

\sloppy

\title{Detecção de Viés Ideológico em Artigos de Notícias Utilizando Aprendizagem Métrica Profunda e Representações Contextuais}

%\author{Jailson Pereira Januário\inst{1}, André Carvalho\inst{2}}


\address{%Instituto de Computação -- Universidade Federal do Amazonas
%  (UFAM)\\
%  Caixa Postal 15.064 -- 91.501-970 -- Manaus -- AM -- Brasil
%  \email{\{jailson,acarvalho\}@iicomp.ufam.edu.br}
%\nextinstitute
%  Department of Computer Science -- University of Durham\\
%  Durham, U.K.
%\nextinstitute
%  Instituto de Computação\\
%  Universidade Federal do Amazonas (UFAM) -- Manaus, AM -- Brasil
%  \email{\{jailson,acarvalho\}@iicomp.ufam.edu.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This study investigates ideological bias identification using metric learning with BERT-based models. It demonstrates that Contrastive and Triplet Loss optimize 
  embedding extraction for political classification, outperforming the literature baseline by 12 percentage points in rigorous evaluations. The model proved competitive 
  against zero-shot LLMs, establishing itself as a robust, efficient alternative that captures semantic nuances beyond outlet memorization, ensuring integrity in analyzing unseen data.
\end{abstract}
     
\begin{resumo} 
  Este estudo investiga a identificação de viés ideológico via aprendizagem métrica com modelos pré-treinados baseados em BERT. 
  Demonstra-se que o uso de Contrastive e Triplet Loss otimiza a extração de embeddings para classificação política, superando o baseline da literatura em 12 pontos percentuais 
  em avaliações rigorosas. O modelo mostrou-se competitivo frente a LLMs em modo zero-shot, consolidando-se como uma alternativa robusta e eficiente que captura nuances semânticas 
  além da memorização de veículos de imprensa, garantindo integridade na análise de dados inéditos.
\end{resumo}


\section{Introdução}\label{sec:intro}
Nos últimos anos, a expansão exponencial de informações online via portais de notícias impõe o desafio de assegurar a imparcialidade dos conteúdos. 
O viés ideológico em artigos pode distorcer a percepção pública e influenciar decisões políticas e resultados eleitorais \cite{gentzkow2006media, chiang2011media}. 
Dada a subjetividade inerente ao discurso, a identificação automatizada dessa inclinação é uma tarefa complexa, tornando o desenvolvimento de métodos precisos de detecção uma área 
de pesquisa altamente relevante para a integridade da informação.

No campo do Processamento de Linguagem Natural (PLN), abordagens buscam automatizar essa detecção via conteúdo textual, hiperlinks e teoria da informação \cite{spinde2022neural,patricia2019link}. 
Contudo, as soluções atuais frequentemente limitam-se a métricas isoladas ou cenários puramente polarizados. A forte dependência de fontes externas compromete a autonomia desses métodos, 
dificultando a criação de sistemas capazes de identificar nuances ideológicas em contextos abrangentes e sem metadados complementares.

Para superar tais limitações, este estudo propõe uma metodologia baseada em aprendizagem métrica para construir espaços de características que aproximam artigos 
de mesma orientação ideológica. Diferente de abordagens restritas a sentenças, esta pesquisa explora o conteúdo integral dos documentos. O trabalho avança ao mitigar 
a dependência de fontes externas e ao superar a divisão bipartidária, incorporando o espectro político de centro nas análises para uma generalização mais robusta.

As contribuições deste estudo incluem a análise do espectro centrista e o desenvolvimento de classificadores independentes de fontes externas. 
Utilizam-se técnicas de \textit{Contrastive} e \textit{Triplet Loss} para gerar espaços de \textit{embeddings} otimizados via arquiteturas pré-treinadas. 
Os resultados demonstram maior eficácia frente às abordagens da literatura, validando o uso de aprendizagem métrica para capturar nuances semânticas e garantir 
robustez na classificação de documentos completos em cenários inéditos.

\section{Trabalhos Relacionados}\label{sec:trabalhos}

A classificação de viés ideológico em portais de notícias fundamenta-se em dimensões analíticas que variam do estrutural ao puramente textual. Tradicionalmente, 
métodos baseados em hiperlinks utilizam informações de cocitação e modelos probabilísticos para estimar a orientação de documentos \cite{efron2004liberal}. Outras abordagens 
exploram redes de comunicação e padrões de consumo para correlacionar a reputação das fontes com as preferências de sua audiência \cite{gentzkow2006media, lin2011more}. 
Tais estratégias iniciais pavimentaram o caminho para a análise de conexões sistêmicas entre veículos de imprensa.

No âmbito do conteúdo textual, as pesquisas investigam desde o enquadramento discursivo até o uso de mecanismos de atenção para capturar orientações implícitas em manchetes \cite{dallmann2015media, gangula-etal-2019-detecting}. 
Estudos demonstraram que, embora o PLN alcance alta acurácia em fontes conhecidas, a generalização para veículos não vistos durante o treino permanece um desafio crítico \cite{baly2020we}. 
Essas técnicas evidenciam que a semântica textual é o indicador mais intuitivo, porém complexo, da inclinação ideológica, exigindo modelos capazes de capturar nuances linguísticas profundas.

Recentemente, LLMs têm sido usados para identificar vieses e investigar inclinações nativas nessas arquiteturas. O modelo \textit{POLITICS} utiliza aprendizagem métrica com \textit{Triplet Loss} 
para comparar artigos sobre o mesmo tema \cite{liu-etal-2022-politics}. Pesquisas com o ChatGPT revelaram preferências ideológicas intrínsecas, enquanto o \textit{framework} \textit{IndiVec} 
foca em indicadores para aumentar a explicabilidade \cite{lin2024indivecexplorationleveraginglarge}. Tais frentes sublinham a necessidade de distinguir entre o viés do conteúdo e o viés 
algorítmico \cite{lin-etal-2025-investigating}.

Para superar as limitações de generalização e dependência externa, este trabalho propõe um método focado exclusivamente no conteúdo integral dos artigos via modelos BERT. 
Ao contrário de abordagens restritas a sentenças, nossa estratégia utiliza aprendizagem métrica para garantir robustez em cenários de avaliação rigorosa. 
Adota-se o trabalho de \cite{baly2020we} como \textit{baseline} principal, por fornecer condições comparativas ideais de treino e avaliação dentro do mesmo \textit{corpus}, 
visando avançar na identificação de nuances semânticas e ideológicas em dados inéditos.

\section{Material e Métodos}\label{sec:material}

A metodologia assume que o viés ideológico se manifesta em padrões discursivos, processando textos via modelos pré-treinados e 
otimizando \textit{embeddings} por \textit{Contrastive} e \textit{Triplet Loss}. Conforme a Figura~\ref{fig:fluxo_dados}, o 
fluxo abrange quatro etapas: definição dos conjuntos de dados, geração de representações por aprendizagem métrica, 
treinamento de classificadores e análise de desempenho. As seções seguintes detalham cada módulo da arquitetura proposta.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/fig_abordagem_proposta_texto.pdf}
\caption{\centering Visão geral do método de detecção de viés ideológico por meio do conteúdo textual de artigos de notícias.}
\label{fig:fluxo_dados}
\end{figure}

\subsection{Dados Experimentais}\label{sec:dados}
Para o desenvolvimento deste estudo, utilizou-se o conjunto de dados \textit{Article Bias Prediction} (ABP) \cite{baly2020we}, composto
por $30.246$ notícias em inglês rotuladas em três categorias (\textit{left, center} e \textit{right}.) A fidedignidade dos rótulos
advém plataforma AllSides\footnote{\url{https://www.allsides.com/media-bias/media-bias-rating-methods}}, que
emprega auditorias rigorosas e revisões da comunidade, conforme ilustrado na Figura~\ref{fig:example_article}. Visando a integridade
da análise, o \textit{corpus} foi pré-processado para remover marcadores de autoria e portais, garantindo que o modelo identifique nuances
linguísticas em vez de apenas a fonte da notícia.


\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/example_areticle.png}
\caption{\centering Exemplo de uma amostra de artigo de notícia com o tópico sobre a pandemia de coronavírus \cite{baly2020we}.}
\label{fig:example_article}
\end{figure}

A robustez metodológica foi validada por dois critérios de particionamento: o \textit{media-bias split} (Tabela~\ref{tab:particoes_media}), que 
segrega veículos para mitigar o vazamento de dados, e o \textit{random split} (Tabela~\ref{tab:particoes_random}), que mantém a consistência 
na distribuição de classes entre treino e validação. Adicionalmente, a generalização foi avaliada com o conjunto \textit{FlipBias} \cite{chen2018learning}, 
contendo $2.781$ eventos sob múltiplas perspectivas. Os modelos seguiram as diretrizes de \cite{lin2024indivecexplorationleveraginglarge,lin-etal-2025-investigating} 
para aferir a robustez das representações em dados não expostos no treinamento.

\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{media-bias split}.} \label{tab:particoes_media}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline 
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left   & 8.861  & 33,32\% & Left   & 1.640 & 69,60\% & Left   & 402 & 30,92\% \\
        Center & 7.488  & 28,16\% & Center & 618   & 26,23\% & Center & 299 & 23,00\% \\
        Right  & 10.241 & 38,51\% & Right  & 98    & 4,15\%  & Right  & 599 & 46,07\% \\ 
        \hline
    \end{tabularx}
\end{table*}

\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{random split}.} \label{tab:particoes_random}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left & 9.750  & 34,84\% & Left & 2.438 & 34,84\% & Left & 402 & 30,92\% \\
        Center   & 7.988  & 28,55\% & Center   & 1.998 & 28,55\% & Center   & 299 & 23,00\% \\ 
        Right  & 10.240 & 36,60\% & Right  & 2.560 & 36,59\% & Right  & 599 & 46,07\% \\
        \hline
    \end{tabularx}
\end{table*}

\subsection{Tarefa de Geração de \textit{Embeddings}}\label{sec:representacoes}

Para a execução da tarefa, a Figura~\ref{fig:fluxo_embeddings} ilustra o fluxo de processamento adotado. O processo inicia-se com a
\textit{tokenização} dos artigos de notícias, seguida pela mineração de exemplos. Esta etapa é fundamental para selecionar amostras
informativas que otimizam a convergência e o aprendizado do modelo.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{./imagens/fig_geracao_embeddings.pdf}
    \caption{\centering Fluxo de treinamento e geração de características para artigos de notícias.}
    \label{fig:fluxo_embeddings}
\end{figure}

Conforme delineado na arquitetura apresentada, empregaram-se dois modelos fundamentados em \textit{Bidirectional Encoder Representations from Transformers (BERT)} \cite{bert}, 
reconhecidos pela eficácia na modelagem de dependências de longo alcance e na extração de relações semânticas granulares \cite{Zhang}. 
A seleção recaiu sobre o DistilBERT \cite{distilbert} e o DistilRoBERTa \cite{roberta}, variantes destiladas que preservam a robustez das arquiteturas originais, 
contudo, apresentam reduções substanciais no custo computacional e nos requisitos de memória.

O modelo \textit{Transformer} processa as sequências de entrada, seguido por uma camada de \textit{Mean Pooling} que consolida 
as representações em um vetor único. O (\textit{fine-tuning}) é regido por estratégias de aprendizagem métrica\footnote{Aprendizagem métrica (ou \textit{metric learning}) refere-se ao uso de algoritmos para aprender uma função de distância que capture a similaridade entre dados.}, 
utilizando as funções de perda \textit{Contrastive Loss} ou \textit{Triplet Loss}. Tal abordagem assegura que os \textit{embeddings} gerados na saída 
posicionem instâncias contextualmente similares em regiões próximas do espaço de representação, otimizando a discriminação entre as classes.

No que se refere ao pré-processamento, as \textit{stopwords} foram preservadas, visto que a arquitetura BERT demonstra eficácia na extração de nuances contextuais 
a partir desses elementos. Por fim, o treinamento foi estabelecido com um limite de $100$ épocas, utilizando o otimizador Adam com 
taxa de aprendizado de $0,0001$ e \textit{batch size} de $16$. Para mitigar o \textit{overfitting} e assegurar a capacidade de 
generalização dos modelos, aplicou-se a técnica de \textit{Early Stopping} com paciência de $30$ ciclos, monitorando-se a 
convergência da função de perda no conjunto de validação.

\subsubsection{Mecanismos de Aproximação e Distanciamento}\label{sec:funcoes}


Nesta abordagem, os codificadores (DistilBERT e DistilRoBERTa) ajustam os pesos de suas camadas para otimizar a 
qualidade dos \textit{embeddings} via \textit{Contrastive Loss} e \textit{Triplet Loss}. 
O objetivo é o aprendizado de representações vetoriais onde instâncias semanticamente similares convirjam no espaço representação, 
enquanto exemplos dissimilaridades sejam repelidos.

A \textit{Contrastive Loss} é aplicada utilizando a distância Euclidiana sobre pares de exemplos, conforme definido na Equação 1:

\begin{equation}
L = \frac{1}{2} (1-y) D^2 + \frac{1}{2} y \{ \max(0, m - D) \}^2
\end{equation}

Onde $y$ representa o rótulo binário (0 para similar, 1 para dissimilar), $D$ denota a distância entre as representações e $m$ é a margem de separação. 

Complementarmente, a \textit{Triplet Loss} utiliza triplas compostas por uma âncora ($a$), um exemplo positivo ($p$) e um negativo ($n$). 
O objetivo, expresso na Equação 2, assegura que a distância entre a âncora e o positivo seja inferior à distância entre a âncora e o negativo por uma margem $m$:

\begin{equation}
L = \max(0, D(a, p) - D(a, n) + m)
\end{equation}

Para otimizar o aprendizado, empregou-se o \textit{mining} de negativos \textit{semi-hard}. Esses exemplos, 
que satisfazem a condição $D(a, p) < D(a, n) + m$, fornecem gradientes mais informativos e 
mitigam o \textit{overfitting} em comparação a negativos \textit{hard} \cite{loss}. Esse processo 
refina a capacidade discriminatória do modelo, permitindo que os \textit{embeddings} 
capturem relações semânticas profundas, como a ideologia de uma notícia, independentemente da fonte de publicação.

\subsection{Tarefa de Classificação: Modelos e Parametrizaçao}\label{sec:classificacao}
Após o mapeamento dos \textit{embeddings}, onde a proximidade entre os veotres reflete a similaridade ideológica das notícias.
A classificação dos artigos foi realizada por meio de três algoritmos: \textit{K-Nearest Neighbors (KNN)}, \textit{K-Means} e
\textit{Multilayer Perceptron (MLP)}. O \textit{KNN} e o \textit{K-Means} foram utilizados para explorar a organização dos dados
por vizinhaça e agrupamento, respectivamente. Para o \textit{KNN}, aplicou-se um \textit{grid search} sistemático para otimização de hiperparâmetros, variando o número de vizinhos ($k$)
entre $5, 10, 15, 20, 25$ e $30$. Já o \textit{K-Means} foi configurado com o número de \textit{clusters} equivalente às classes
presentes no conjunto de dados ABP.

A rede \textit{MLP} foi estruturada com duas camadas densas (512 e 256 neurônios). Adotou-se a função de ativação \textit{ReLU}
para garantir um treinamento mais rápido e estável \cite{Zhang}, enquanto a camada de saída utilizou a \textit{softmax} para a 
classificação final. O modelo otimizado com o algoritmo \textit{Adam} e a função de perda
\textit{Categorical Cross-Entropy}, escolhas consolidadas na literatura para problemas multiclasse \cite{goodfellow2016deep}.

A confiabilidade do experimento foi assegurada pela validação cruzada estritificada (5-fold). Esse procedimento garante que a proporção das classes
seja mantida em todas as etapas, evitando resultados enviesados e permitindo medir com precisão a capacidade do modelo em classificar novos dados \cite{brink2016real}.

\subsection{Avaliação de Desempenho}

O desempenho dos modelos de classificação será avaliado pelas métricas de Acurácia e \textit{Macro F1-score}.
A Acurácia (Equação~\ref{eq:accuracy}) fornece uma medida geral da taxa de acerto para o conjunto de classes $C$.
Complementarmente, o \textit{Macro F1-score} (Equação~\ref{eq:macrof1}) permite uma avaliação equilibrada entre as
classes, mitigando distorções causadas por eventuais desbalanceamento no conjunto de dados.

As métricas são formalmente definidas conforme segue:

%\begin{equation}\label{eq:accuracy}
%\text{Acurácia} = \frac{1}{|C|} \sum_{c \in C} \left ( \frac{TP_c + TN_c}{TP_c + TN_c + FP_c + FN_c} \right )
%\end{equation}

%\begin{equation}\label{eq:macrof1}
%\text{Macro } F1 = \frac{1}{C} \sum_{c \in C} F1_c
%\end{equation}

\noindent
\begin{minipage}{0.50\linewidth}
\begin{equation}\label{eq:accuracy}
\text{Acurácia} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
\end{minipage}\hfill
\begin{minipage}{0.48\linewidth}
\begin{equation}\label{eq:macrof1}
\text{Macro } F1 = \frac{1}{|C|} \sum_{c \in C} F1_c
\end{equation}
\end{minipage}

Em que $F1_c$ representa a média harmônica entre a Precisão ($P_c$) e a Revocação ($R_c$) para cada classe:

%\begin{equation}\label{eq:prec_rec} 
%  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c} 
%\end{equation}

%\begin{equation}\label{eq:f1_calc} 
%  F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
%\end{equation}

\
\begin{equation}\label{eq:prec_rec} 
  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c}, \quad F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
\end{equation}

Neste contexto, $TP$, $TN$, $FP$ e $FN$ representam, respectivamente, os verdadeiros positivos, 
verdadeiros negativos, falsos positivos e falsos negativos. 

A validação da hipótese de pesquisa --- de que o discurso textual reflete o viés ideológico --- dar-se-á 
mediante a obtenção de altos índices em ambas as métricas. 
Espera-se que valores elevados de \textit{Macro F1-score} confirmem a capacidade discriminatória do modelo entre
as diferentes vertentes ideológicas, assegurando que o desempenho não seja reflexo de uma classe majoritária no conjunto de dados.

%\subsection{Configuração dos Experimentos e Espaço de Busca}

%A exploração da configuração ótima para os modelos foi formalizada por uma função de desempenho $\mathcal{P}$, que parametriza 
%as variações arquiteturais do método proposto conforme a Equação~\ref{eq:funcao_experimento}. Nesta formulação, $S$ 
%representa o protocolo de particionamento dos dados (\textit{media-bias} ou \textit{random split}), $R$ define o codificador 
%empregado na geração dos \textit{embeddings}, $L$ denota a função de perda aplicada ao aprendizado de representação em $R$, e $C$ 
%designa o algoritmo de classificação final.

%\begin{equation}\label{eq:funcao_experimento} 
%  \mathcal{P} = f(S, R, L, C) 
%\end{equation}

%O objetivo experimental consiste em identificar a tupla de parâmetros $\hat{e}$ que maximize o desempenho global do método proposto. 
%Tal busca é definida matematicamente pela operação de \textit{argmax} apresentada na Equação~\ref{eq:argmax}, permitindo a 
%identificação sistemática da arquitetura que apresenta os melhores índices de acurácia e \textit{Macro F1-score} entre todas as 
%combinações testadas.

%\begin{equation}\label{eq:argmax} 
%  \hat{e} = \arg\max f(S, R, L, C) 
%\end{equation}

\subsection{Ambiente de Execução}

A linguagem Python, com as bibliotecas NumPy, Pandas, Scikit-Learn e PyTorch, foi a ferramenta primária para implementação e avaliação dos modelos. 
Os experimentos ocorreram em um servidor equipado com processador Intel Xeon W-2235, $128$ GB de RAM e GPU NVIDIA RTX $8000$ ($48$ GB VRAM), 
visando a aceleração em hardware. %Comprometendo-se com a transparência e a reprodutibilidade técnica, o código-fonte, 
%hiperparâmetros e \textit{scripts} de pré-processamento estão publicamente disponíveis\footnote{\url{https://github.com/jailsonpj/detecting-ideological-bias}}.

\section{Resultados e Discussão} \label{sec:resultados}

Os experimentos foram conduzidos seguindo a metodologia proposta, totalizando $24$ configurações que integraram os modelos DistilBERT e DistilRoBERTa, 
funções de perda (\textit{Contrastive Loss} e \textit{Triplet Loss}) e classificadores (\textit{KNN, K-Means} e \textit{MLP}). 
Esta abordagem permitiu uma análise sistemática da sensibilidade dos modelos nos cenários \textit{random split} e \textit{media-bias split}.

\subsection{Desempenho no Conjunto de Dados ABP}

Os resultados consolidados na Tabela~\ref{tab:resultados_ajustados} demonstram que a utilização de aprendizagem métrica, especificamente a \textit{Contrastive Loss}, 
favorece significativamente a separação vetorial no espaço de \textit{embeddings} para a tarefa de viés ideológico.

\begin{table}[!ht]
\centering
\caption{Desempenho comparativo (em \%) no conjunto de dados ABP utilizando as divisões \textit{media-bias split} e \textit{random split}.}
\label{tab:resultados_ajustados}
\resizebox{\textwidth}{!}{% % Adiciona o parâmetro de ajuste à largura do texto
\begin{tabular}{@{}ccccc@{}}
\toprule
\textbf{Cenário}                                                                     & \textbf{Modelo}                                                       & \begin{tabular}[c]{@{}c@{}} \textbf{Configuração}\\ \textbf{(Repre. / Fun. de Perda / Classificador)}\end{tabular} & \textbf{Macro F1-Score} & \textbf{Acurácia} \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}ABP\\ (media- bias split)\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 4)\end{tabular}  & DistilRoBERTa / Constrastive / KNN                                           & 45,44          & 48,89    \\ 
                                                                                   & Baly el al., (2020)                                          & BERT / - / BERT                                                              & 33,53          & 36,75    \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}ABP \\ (random split)\end{tabular}}     & \begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 16)\end{tabular} & DistilRoBERTa / Constrastive / KNN                                           & 83,90          & 83,89    \\ 
                                                                                   & Baly el al., (2020)                                          & BERT / - / BERT                                                              & 80,19          & 79,83    \\ \bottomrule
\end{tabular}%
}
\end{table}

No cenário \textit{media-bias split}, o modelo proposto superou o baseline de Baly et al.[2020] em aproximadamente $12$ pontos percentuais. 
Este resultado é particularmente relevante, pois o \textit{media-bias split} exige que o modelo identifique nuances ideológicas em veículos de 
imprensa nunca vistos durante o treinamento. Contudo, a queda de desempenho em relação ao \textit{random split} ($83,90\%$) evidencia que a 
presença de fontes comuns facilita a predição por meio da memorização de padrões específicos do veículo, e não necessariamente da 
ideologia pura.
\subsection{Avaliação de Generalização}

Para testar a robustez em cenários de estresse rigoroso, o modelo foi submetido ao dataset \textit{FlipBias} sem ajuste fino adicional. 
Embora os índices de \textit{Macro F1-score} ($47,00\%$ no Exp. 16), apresentados na Tabela~\ref{tab:resultados_flibias}, tenham sido inferiores aos modelos \textit{in-domain}\footnote{In-domain refere-se a uma situação em que os dados utilizados 
para treinar um modelo de aprendizagem de máquina e os dados usados para testá-lo vêm da 
mesma distribuição, contexto ou fonte.} de Lin et al. [2024, 2025], 
os dados sugerem que a arquitetura captura estruturas ideológicas fundamentais que transcendem o domínio original.

\begin{table}[!ht]
\centering
\caption{Desempenho comparativo (em \%) no conjunto de dados FlipBias.}
\label{tab:resultados_flibias}
\resizebox{\textwidth}{!}{% % Parâmetro para ajustar ao texto
\begin{tabular}{@{}cccc@{}}
\toprule
\textbf{Autor}                                              & \textbf{\begin{tabular}[c]{@{}c@{}}Modelo / Configuração \end{tabular}} & \textbf{Estratégia} & \textbf{Macro F1-Score} \\ \midrule
Lin et al. (2024)                                           & BERT                                                                              & Fine-tuning                                & 86,20                   \\
Lin et al. (2025)                                           & GPT 3.5                                                                           & Fine-tuning                                & 77,82                   \\
\begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 16)\end{tabular} & DistilRoBERTa / Constrastive / KNN                                               & Fine-tuning                               & 47,00                   \\
\begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 4)\end{tabular}  & DistilRoBERTa / Constrastive / KNN                                               & Fine-tuning                               & 28,21                   \\ \bottomrule
\end{tabular}%
}
\end{table} 
\subsection{Comparação com Modelos de Linguagem de Larga Escala (LLMs)}

Uma análise comparativa foi realizada com uma amostra de $90$ instâncias do teste \textit{media-bias split} para situar o modelo 
frente a LLMs de última geração. Observa-se que o modelo proposto, mesmo sendo uma arquitetura destilada e leve (\textit{DistilRoBERTa}), 
superou o desempenho \textit{zero-shot} do DeepSeek ($16,0\%$) e aproximou-se da performance do Gemini 3 ($34,0\%$). 

\begin{table}[ht]
\centering
\caption{Comparação com LLMs (Amostra Aleatória)}
\label{tab:llm}
\begin{tabular}{@{}llc@{}}
\toprule
\textbf{Modelo} & \textbf{Estratégia} & \textbf{Macro F1-Score} \\ \midrule
Gemini 3        & Zero-Shot           & 34,0\%                  \\
Proposto (Exp. 4) & Fine-tuning       & 27,0\%                  \\
DeepSeek        & Zero-Shot           & 16,0\%                  \\ \bottomrule
\end{tabular}
\end{table}

É fundamental ressaltar que, embora o desempenho absoluto seja inferior ao Gemini 3, o modelo proposto é ordens de magnitude menor em termos de parâmetros 
e requisitos computacionais. Enquanto LLMs exigem infraestruturas massivas de nuvem, a arquitetura baseada em aprendizagem métrica aqui apresentada 
é perfeitamente viável para ambientes com recursos computacionais restritos. Isso valida a eficácia da \textit{Contrastive Loss} em 
gerar representações discriminatórias competitivas, priorizando a eficiência e a viabilidade prática em cenários limitados.

\section{Considerações Finais}

Este estudo objetivou avaliar a eficácia da aprendizagem métrica na identificação de viés ideológico, integrando modelos pré-treinados e 
funções de perda contrastivas. Os resultados demonstram que a \textit{Contrastive Loss} otimiza a separação vetorial, superando o baseline de 
\cite{baly2020we} em $12$ pontos percentuais no cenário \textit{media-bias split}. A arquitetura mostrou-se competitiva frente a LLMs em modo \textit{zero-shot}, 
validando a viabilidade de modelos leves e eficientes para a análise de nuances discursivas.

Para trabalhos futuros, pretende-se explorar técnicas de \textit{Domain Adaptation} para otimizar a transferência de conhecimento e elevar o desempenho em 
dados de fontes não expostas durante o treinamento. Além disso, planeja-se investigar o comportamento de LLMs sob estratégias de \textit{Few-Shot} e \textit{Fine-Tuning}, permitindo 
uma comparação mais consistente com a arquitetura proposta. Tais avanços visam mitigar a memorização de padrões específicos de veículos e consolidar a robustez do modelo em 
cenários de generalização rigorosa.

\bibliographystyle{sbc}
\bibliography{sbc-template}


\end{document}
