\documentclass[12pt]{article}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{array} % Necessário para o >{\centering\arraybackslash}
\usepackage{amsmath}
\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}

\sloppy

\title{Instructions for Authors of SBC Conferences\\ Papers and Abstracts}

%\author{Jailson Pereira Januário\inst{1}, André Carvalho\inst{2}}


\address{%Instituto de Computação -- Universidade Federal do Amazonas
%  (UFAM)\\
%  Caixa Postal 15.064 -- 91.501-970 -- Manaus -- AM -- Brasil
%  \email{\{jailson,acarvalho\}@iicomp.ufam.edu.br}
%\nextinstitute
%  Department of Computer Science -- University of Durham\\
%  Durham, U.K.
%\nextinstitute
%  Instituto de Computação\\
%  Universidade Federal do Amazonas (UFAM) -- Manaus, AM -- Brasil
%  \email{\{jailson,acarvalho\}@iicomp.ufam.edu.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This meta-paper describes the style to be used in articles and short papers
  for SBC conferences. For papers in English, you should add just an abstract
  while for the papers in Portuguese, we also ask for an abstract in
  Portuguese (``resumo''). In both cases, abstracts should not have more than
  10 lines and must be in the first page of the paper.
\end{abstract}
     
\begin{resumo} 
  Este meta-artigo descreve o estilo a ser usado na confecção de artigos e
  resumos de artigos para publicação nos anais das conferências organizadas
  pela SBC. É solicitada a escrita de resumo e abstract apenas para os artigos
  escritos em português. Artigos em inglês deverão apresentar apenas abstract.
  Nos dois casos, o autor deve tomar cuidado para que o resumo (e o abstract)
  não ultrapassem 10 linhas cada, sendo que ambos devem estar na primeira
  página do artigo.
\end{resumo}


\section{Introdução}\label{sec:intro}

\section{Trabalhos Relacionados}\label{sec:trabalhos}

\section{Material e Métodos}\label{sec:material}
A metodologia fundamenta-se na premissa de que o viés ideológico se manifesta em padrões discursivos e semânticos recorrentes, processando conteúdos 
textuais via modelos pré-treinados para geração de \textit{embeddings} otimizados por \textit{Contrastive} e \textit{Triplet Loss}. 
Como ilustrado na Figura~\ref{fig:fluxo_dados}, o fluxo de trabalho compreende quatro etapas principais: a definição de conjuntos de treino e 
teste baseados na literatura, a geração de representações vetoriais via aprendizagem métrica, o treinamento de classificadores sobre vetores 
otimizados e a análise sistemática do desempenho. As seções que seguem descrevem detalhadamente cada módulo integrante da arquitetura apresentada.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/fig_abordagem_proposta_texto.pdf}
\caption{\centering Visão geral do método de detecção de viés ideológico por meio do conteúdo textual de artigos de notícias.}
\label{fig:fluxo_dados}
\end{figure}

\subsection{Dados Experimentais}\label{sec:dados}

Para o desenvolvimento deste estudo, utilizou-se o conjunto de dados \textit{Article Bias Prediction} (ABP), proposto por Baly $et$ $al.$ [2020].%\cite{baly2020we}.
 O \textit{corpus} compreende $30.246$ artigos de notícias em língua inglesa, classificados de forma supervisionada nas
categorias de viés ideológico: \textit{left}, \textit{center} e \textit{right}. A confiabilidade dos rótulos advém da plataforma AllSides\footnote{\url{https://www.allsides.com/media-bias/media-bias-rating-methods}},
que emprega um processo rigoroso de auditoria -- incluindo revisões de terceiros e \textit{feedback} da comunidade -- garantindo que anotações
reflitam com precisão a orientação política dos textos. A Figura~\ref{fig:example_article} ilustra um exemplo de como um tópico de notícia foi classificado de acordo com a ideologia presente no texto.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{./imagens/example_areticle.png}
\caption{\centering Exemplo de uma amostra de artigo de notícia com o tópico sobre a pandemia de coronavírus \cite{baly2020we}.}
\label{fig:example_article}
\end{figure}

O ABP apresenta elevada diversidade temática, abrangendo desde processos eleitorais até questões sociais complexas.
Visando assegurar que os modelos de aprendizado de máquina capturam a ideologia expressa linguisticamente, e não apenas identifiquem a fonte de notícia,
os autores realizaram um pré-processamento para remover marcadores explícitos, como nomes de autores e de portais. Essa preocupação é
fundamental para garantir a generalização do modelo e a integridade da análise discursiva, evitando que o classificador aprendizada
vieses específicos de veículo de imprensa em vez de padrões semânticos.

A robustez da avaliação foi garantida através de dois métodos de particionamento: o \textit{random split} e o \textit{media-bias split}. 
Na Tabela~\ref{tab:particoes_media}, observa-se a configuração do \textit{media-bias split}, no qual as fontes são segregadas para garantir 
que o modelo seja testado em veículos não expostos durante o treinamento, mitigando o vazamento de dados. Em contraste, o \textit{random-split}
permite a sobreposição de fontes entre as partições, mantendo a consistência na distribuição de classes entre treino e validação, como apresentado
na Tabela~\ref{tab:particoes_random}. Neste trabalho, a totalidade das amostras do ABP foi empregada em todas as etapas metodológicas,
desde a geração de \textit{embeddings} até o treinamento e avaliação final.


\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{media-bias split}.} \label{tab:particoes_media}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline \hline
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left   & 8.861  & 33,32\% & Left   & 1.640 & 69,60\% & Left   & 402 & 30,92\% \\
        Center & 7.488  & 28,16\% & Center & 618   & 26,23\% & Center & 299 & 23,00\% \\
        Right  & 10.241 & 38,51\% & Right  & 98    & 4,15\%  & Right  & 599 & 46,07\% \\ 
        \hline \hline
    \end{tabularx}
\end{table*}

\begin{table*}[!ht]
    \caption{Estatísticas da partição \textit{random split}.} \label{tab:particoes_random}
    \centering
    \begin{tabularx}{\textwidth}{@{} *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} | *{3}{>{\centering\arraybackslash}X} @{}}
        \hline \hline
        \multicolumn{3}{c|}{\textbf{Treino}} & \multicolumn{3}{c|}{\textbf{Validação}} & \multicolumn{3}{c}{\textbf{Teste}} \\ 
        \hline
        \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} & \textit{Viés} & \textit{Total} & \textit{\%} \\ 
        \hline
        Left & 9.750  & 34,84\% & Left & 2.438 & 34,84\% & Left & 402 & 30,92\% \\
        Center   & 7.988  & 28,55\% & Center   & 1.998 & 28,55\% & Center   & 299 & 23,00\% \\ 
        Right  & 10.240 & 36,60\% & Right  & 2.560 & 36,59\% & Right  & 599 & 46,07\% \\
        \hline \hline
    \end{tabularx}
\end{table*}

\subsubsection{Avaliação de Generalização: Dataset FlipBias}\label{subsec:flipbias}

Para avaliar o poder de generalização dos modelos experimentados, utilizou-se o conjunto de dados \textit{FlipBias} \cite{chen2018learning}. 
Extraído da plataforma AllSides, o \textit{corpus} organiza-se em $2.781$ eventos noticiosos, cada qual coberto por perspectivas de diferentes inclinações 
políticas (\textit{left}, \textit{center} e \textit{right}). 

Para assegurar a comparabilidade dos resultados, os modelos foram submetidos às condições de avaliação estabelecidas por \cite{lin2024indivecexplorationleveraginglarge,lin-etal-2025-investigating}. 
Essa abordagem permite verificar a robustez das representações na identificação de nuances ideológicas, garantindo que o desempenho observado reflita uma capacidade real de abstração frente a dados 
não utilizados durante o treinamento.

\subsection{Tarefa de Geração de \textit{Embeddings}}\label{sec:representacoes}

Para a execução da tarefa, a Figura~\ref{fig:fluxo_embeddings} ilustra o fluxo de processamento adotado. O processo inicia-se com a
\textit{tokenização} dos artigos de notícias, seguida pela mineração de exemplos. Esta etapa é fundamental para selecionar amostras
informativas que otimizam a convergência e o aprendizado do modelo.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{./imagens/fig_geracao_embeddings.pdf}
    \caption{\centering Fluxo de treinamento e geração de características para artigos de notícias.}
    \label{fig:fluxo_embeddings}
\end{figure}

Conforme delineado na arquitetura apresentada, empregaram-se dois modelos fundamentados em \textit{Bidirectional Encoder Representations from Transformers (BERT)} \cite{bert}, 
reconhecidos pela eficácia na modelagem de dependências de longo alcance e na extração de relações semânticas granulares \cite{Zhang}. 
A seleção recaiu sobre o DistilBERT \cite{distilbert} e o DistilRoBERTa \cite{roberta}, variantes destiladas que preservam a robustez das arquiteturas originais, 
contudo, apresentam reduções substanciais no custo computacional e nos requisitos de memória.

O modelo \textit{Transformer} processa as sequências de entrada, seguido por uma camada de \textit{Mean Pooling} que consolida 
as representações em um vetor único. O (\textit{fine-tuning}) é regido por estratégias de aprendizagem métrica\footnote{Aprendizagem métrica (ou \textit{metric learning}) refere-se ao uso de algoritmos para aprender uma função de distância que capture a similaridade entre dados.}, 
utilizando as funções de perda \textit{Contrastive Loss} ou \textit{Triplet Loss}. Tal abordagem assegura que os \textit{embeddings} gerados na saída 
posicionem instâncias contextualmente similares em regiões próximas do espaço de representação, otimizando a discriminação entre as classes.

No que se refere ao pré-processamento, as \textit{stopwords} foram preservadas, visto que a arquitetura BERT demonstra eficácia na extração de nuances contextuais 
a partir desses elementos. Por fim, o treinamento foi estabelecido com um limite de $100$ épocas, utilizando o otimizador Adam com 
taxa de aprendizado de $0,0001$ e \textit{batch size} de $16$. Para mitigar o \textit{overfitting} e assegurar a capacidade de 
generalização dos modelos, aplicou-se a técnica de \textit{Early Stopping} com paciência de $30$ ciclos, monitorando-se a 
convergência da função de perda no conjunto de validação.

\subsubsection{Mecanismos de Aproximação e Distanciamento}\label{sec:funcoes}


Nesta abordagem, os codificadores (DistilBERT e DistilRoBERTa) ajustam os pesos de suas camadas para otimizar a 
qualidade dos \textit{embeddings} via \textit{Contrastive Loss} e \textit{Triplet Loss}. 
O objetivo é o aprendizado de representações vetoriais onde instâncias semanticamente similares convirjam no espaço representação, 
enquanto exemplos dissimilaridades sejam repelidos.

A \textit{Contrastive Loss} é aplicada utilizando a distância Euclidiana sobre pares de exemplos, conforme definido na Equação 1:

\begin{equation}
L = \frac{1}{2} (1-y) D^2 + \frac{1}{2} y \{ \max(0, m - D) \}^2
\end{equation}

Onde $y$ representa o rótulo binário (0 para similar, 1 para dissimilar), $D$ denota a distância entre as representações e $m$ é a margem de separação. 

Complementarmente, a \textit{Triplet Loss} utiliza triplas compostas por uma âncora ($a$), um exemplo positivo ($p$) e um negativo ($n$). 
O objetivo, expresso na Equação 2, assegura que a distância entre a âncora e o positivo seja inferior à distância entre a âncora e o negativo por uma margem $m$:

\begin{equation}
L = \max(0, D(a, p) - D(a, n) + m)
\end{equation}

Para otimizar o aprendizado, empregou-se o \textit{mining} de negativos \textit{semi-hard}. Esses exemplos, 
que satisfazem a condição $D(a, p) < D(a, n) + m$, fornecem gradientes mais informativos e 
mitigam o \textit{overfitting} em comparação a negativos \textit{hard} \cite{loss}. Esse processo 
refina a capacidade discriminatória do modelo, permitindo que os \textit{embeddings} 
capturem relações semânticas profundas, como a ideologia de uma notícia, independentemente da fonte de publicação.

\subsection{Tarefa de Classificação: Modelos e Parametrizaçao}\label{sec:classificacao}
Após o mapeamento dos \textit{embeddings}, onde a proximidade entre os veotres reflete a similaridade ideológica das notícias.
A classificação dos artigos foi realizada por meio de três algoritmos: \textit{K-Nearest Neighbors (KNN)}, \textit{K-Means} e
\textit{Multilayer Perceptron (MLP)}. O \textit{KNN} e o \textit{K-Means} foram utilizados para explorar a organização dos dados
por vizinhaça e agrupamento, respectivamente. Para o \textit{KNN}, aplicou-se um \textit{grid search} sistemático para otimização de hiperparâmetros, variando o número de vizinhos ($k$)
entre $5, 10, 15, 20, 25$ e $30$. Já o \textit{K-Means} foi configurado com o número de \textit{clusters} equivalente às classes
presentes no conjunto de dados ABP.

A rede \textit{MLP} foi estruturada com duas camadas densas (512 e 256 neurônios). Adotou-se a função de ativação \textit{ReLU}
para garantir um treinamento mais rápido e estável \cite{Zhang}, enquanto a camada de saída utilizou a \textit{softmax} para a 
classificação final. O modelo otimizado com o algoritmo \textit{Adam} e a função de perda
\textit{Categorical Cross-Entropy}, escolhas consolidadas na literatura para problemas multiclasse \cite{goodfellow2016deep}.

A confiabilidade do experimento foi assegurada pela validação cruzada estritificada (5-fold). Esse procedimento garante que a proporção das classes
seja mantida em todas as etapas, evitando resultados enviesados e permitindo medir com precisão a capacidade do modelo em classificar novos dados \cite{brink2016real}.

\subsection{Avaliação de Desempenho}

O desempenho dos modelos de classificação será avaliado pelas métricas de Acurácia e \textit{Macro F1-score}.
A Acurácia (Equação~\ref{eq:accuracy}) fornece uma medida geral da taxa de acerto para o conjunto de classes $C$.
Complementarmente, o \textit{Macro F1-score} (Equação~\ref{eq:macrof1}) permite uma avaliação equilibrada entre as
classes, mitigando distorções causadas por eventuais desbalanceamento no conjunto de dados.

As métricas são formalmente definidas conforme segue:

%\begin{equation}\label{eq:accuracy}
%\text{Acurácia} = \frac{1}{|C|} \sum_{c \in C} \left ( \frac{TP_c + TN_c}{TP_c + TN_c + FP_c + FN_c} \right )
%\end{equation}

%\begin{equation}\label{eq:macrof1}
%\text{Macro } F1 = \frac{1}{C} \sum_{c \in C} F1_c
%\end{equation}

\noindent
\begin{minipage}{0.50\linewidth}
\begin{equation}\label{eq:accuracy}
\text{Acurácia} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
\end{minipage}\hfill
\begin{minipage}{0.48\linewidth}
\begin{equation}\label{eq:macrof1}
\text{Macro } F1 = \frac{1}{|C|} \sum_{c \in C} F1_c
\end{equation}
\end{minipage}

Em que $F1_c$ representa a média harmônica entre a Precisão ($P_c$) e a Revocação ($R_c$) para cada classe:

%\begin{equation}\label{eq:prec_rec} 
%  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c} 
%\end{equation}

%\begin{equation}\label{eq:f1_calc} 
%  F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
%\end{equation}

\
\begin{equation}\label{eq:prec_rec} 
  P_c = \frac{TP_c}{TP_c + FP_c}, \quad R_c = \frac{TP_c}{TP_c + FN_c}, \quad F1_c = 2 \times \frac{P_c \times R_c}{P_c + R_c} 
\end{equation}

Neste contexto, $TP$, $TN$, $FP$ e $FN$ representam, respectivamente, os verdadeiros positivos, 
verdadeiros negativos, falsos positivos e falsos negativos. 

A validação da hipótese de pesquisa --- de que o discurso textual reflete o viés ideológico --- dar-se-á 
mediante a obtenção de altos índices em ambas as métricas. 
Espera-se que valores elevados de \textit{Macro F1-score} confirmem a capacidade discriminatória do modelo entre
as diferentes vertentes ideológicas, assegurando que o desempenho não seja reflexo de uma classe majoritária no conjunto de dados.

%\subsection{Configuração dos Experimentos e Espaço de Busca}

%A exploração da configuração ótima para os modelos foi formalizada por uma função de desempenho $\mathcal{P}$, que parametriza 
%as variações arquiteturais do método proposto conforme a Equação~\ref{eq:funcao_experimento}. Nesta formulação, $S$ 
%representa o protocolo de particionamento dos dados (\textit{media-bias} ou \textit{random split}), $R$ define o codificador 
%empregado na geração dos \textit{embeddings}, $L$ denota a função de perda aplicada ao aprendizado de representação em $R$, e $C$ 
%designa o algoritmo de classificação final.

%\begin{equation}\label{eq:funcao_experimento} 
%  \mathcal{P} = f(S, R, L, C) 
%\end{equation}

%O objetivo experimental consiste em identificar a tupla de parâmetros $\hat{e}$ que maximize o desempenho global do método proposto. 
%Tal busca é definida matematicamente pela operação de \textit{argmax} apresentada na Equação~\ref{eq:argmax}, permitindo a 
%identificação sistemática da arquitetura que apresenta os melhores índices de acurácia e \textit{Macro F1-score} entre todas as 
%combinações testadas.

%\begin{equation}\label{eq:argmax} 
%  \hat{e} = \arg\max f(S, R, L, C) 
%\end{equation}

\subsection{Ambiente de Execução}

A linguagem Python, com as bibliotecas NumPy, Pandas, Scikit-Learn e PyTorch, foi a ferramenta primária para implementação e avaliação dos modelos. 
Os experimentos ocorreram em um servidor equipado com processador Intel Xeon W-2235, $128$ GB de RAM e GPU NVIDIA RTX $8000$ ($48$ GB VRAM), 
visando a aceleração em hardware. Comprometendo-se com a transparência e a reprodutibilidade técnica, o código-fonte, 
hiperparâmetros e \textit{scripts} de pré-processamento estão publicamente disponíveis\footnote{\url{https://github.com/jailsonpj/detecting-ideological-bias}}.

\section{Resultados e Discussão} \label{sec:resultados}

Os experimentos foram conduzidos seguindo a metodologia proposta, totalizando $24$ configurações que integraram os modelos DistilBERT e DistilRoBERTa, 
funções de perda (\textit{Contrastive Loss} e \textit{Triplet Loss}) e classificadores (\textit{KNN, K-Means} e \textit{MLP}). 
Esta abordagem permitiu uma análise sistemática da sensibilidade dos modelos nos cenários \textit{random split} e \textit{media-bias split}.

\subsection{Desempenho no Conjunto de Dados ABP}

Os resultados consolidados na Tabela~\ref{tab:resultados_ajustados} demonstram que a utilização de aprendizagem métrica, especificamente a \textit{Contrastive Loss}, 
favorece significativamente a separação vetorial no espaço de \textit{embeddings} para a tarefa de viés ideológico.

\begin{table}[!ht]
\centering
\caption{Desempenho comparativo (em \%) no conjunto de dados ABP utilizando as divisões \textit{media-bias split} e \textit{random split}.}
\label{tab:resultados_ajustados}
\resizebox{\textwidth}{!}{% % Adiciona o parâmetro de ajuste à largura do texto
\begin{tabular}{@{}ccccc@{}}
\toprule
\textbf{Cenário}                                                                     & \textbf{Modelo}                                                       & \begin{tabular}[c]{@{}c@{}} \textbf{Configuração}\\ \textbf{(Repre. / Fun. de Perda / Classificador)}\end{tabular} & \textbf{Macro F1-Score} & \textbf{Acurácia} \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}ABP\\ (media- bias split)\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 4)\end{tabular}  & DistilRoBERTa / Constrastive / KNN                                           & 45,44          & 48,89    \\ 
                                                                                   & Baly el al., (2020)                                          & BERT / - / BERT                                                              & 33,53          & 36,75    \\ \midrule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}ABP \\ (random split)\end{tabular}}     & \begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 16)\end{tabular} & DistilRoBERTa / Constrastive / KNN                                           & 83,90          & 83,89    \\ 
                                                                                   & Baly el al., (2020)                                          & BERT / - / BERT                                                              & 80,19          & 79,83    \\ \bottomrule
\end{tabular}%
}
\end{table}

No cenário \textit{media-bias split}, o modelo proposto superou o baseline de Baly et al.[2020] em aproximadamente $12$ pontos percentuais. 
Este resultado é particularmente relevante, pois o \textit{media-bias split} exige que o modelo identifique nuances ideológicas em veículos de 
imprensa nunca vistos durante o treinamento. Contudo, a queda de desempenho em relação ao \textit{random split} ($83,90\%$) evidencia que a 
presença de fontes comuns facilita a predição por meio da memorização de padrões específicos do veículo, e não necessariamente da 
ideologia pura.

\subsection{Avaliação de Generalização}

Para testar a robustez em cenários de estresse rigoroso, o modelo foi submetido ao dataset \textit{FlipBias} sem ajuste fino adicional. 
Embora os índices de \textit{Macro F1-score} ($47,00\%$ no Exp. 16), apresentados na Tabela~\ref{tab:resultados_flibias}, tenham sido inferiores aos modelos \textit{in-domain}\footnote{In-domain refere-se a uma situação em que os dados utilizados 
para treinar um modelo de aprendizagem de máquina e os dados usados para testá-lo vêm da 
mesma distribuição, contexto ou fonte.} de Lin et al. [2024, 2025], 
os dados sugerem que a arquitetura captura estruturas ideológicas fundamentais que transcendem o domínio original.

\begin{table}[!ht]
\centering
\caption{Desempenho comparativo (em \%) no conjunto de dados FlipBias.}
\label{tab:resultados_flibias}
\resizebox{\textwidth}{!}{% % Parâmetro para ajustar ao texto
\begin{tabular}{@{}cccc@{}}
\toprule
\textbf{Autor}                                              & \textbf{\begin{tabular}[c]{@{}c@{}}Modelo / Configuração \end{tabular}} & \textbf{Estratégia} & \textbf{Macro F1-Score} \\ \midrule
Lin et al. (2024)                                           & BERT                                                                              & Fine-tuning                                & 86,20                   \\
Lin et al. (2025)                                           & GPT 3.5                                                                           & Fine-tuning                                & 77,82                   \\
\begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 16)\end{tabular} & DistilRoBERTa / Constrastive / KNN                                               & Fine-tuning                               & 47,00                   \\
\begin{tabular}[c]{@{}c@{}}Proposto\\ (Exp. 4)\end{tabular}  & DistilRoBERTa / Constrastive / KNN                                               & Fine-tuning                               & 28,21                   \\ \bottomrule
\end{tabular}%
}
\end{table} 
\subsection{Comparação com Modelos de Linguagem de Larga Escala (LLMs)}

Uma análise comparativa foi realizada com uma amostra de $90$ instâncias do teste \textit{media-bias split} para situar o modelo 
frente a LLMs de última geração. Observa-se que o modelo proposto, mesmo sendo uma arquitetura destilada e leve (\textit{DistilRoBERTa}), 
superou o desempenho \textit{zero-shot} do DeepSeek ($16,0\%$) e aproximou-se da performance do Gemini 3 ($34,0\%$). 

\begin{table}[ht]
\centering
\caption{Comparação com LLMs (Amostra Aleatória)}
\label{tab:llm}
\begin{tabular}{@{}llc@{}}
\toprule
\textbf{Modelo} & \textbf{Estratégia} & \textbf{Macro F1-Score} \\ \midrule
Gemini 3        & Zero-Shot           & 34,0\%                  \\
Proposto (Exp. 4) & Fine-tuning       & 27,0\%                  \\
DeepSeek        & Zero-Shot           & 16,0\%                  \\ \bottomrule
\end{tabular}
\end{table}

É fundamental ressaltar que, embora o desempenho absoluto seja inferior ao Gemini 3, o modelo proposto é ordens de magnitude menor em termos de parâmetros 
e requisitos computacionais. Enquanto LLMs exigem infraestruturas massivas de nuvem, a arquitetura baseada em aprendizagem métrica aqui apresentada 
é perfeitamente viável para ambientes com recursos computacionais restritos. Isso valida a eficácia da \textit{Contrastive Loss} em 
gerar representações discriminatórias competitivas, priorizando a eficiência e a viabilidade prática em cenários limitados.


\section{Considerações Finais}

Este estudo investigou o impacto da aprendizagem métrica na classificação de viés político, revelando que a \textit{Contrastive Loss} 
integrada ao \textit{DistilRoBERTa} oferece uma base robusta para a separação semântica de discursos. Os resultados no conjunto ABP 
demonstram que a arquitetura proposta supera \textit{baselines} consolidados mesmo no desafiador cenário \textit{media-bias split}, 
mantendo uma capacidade de discernimento superior à literatura ao lidar com veículos de mídia inéditos. Evidenciou-se que, 
embora o desempenho seja otimizado pela proximidade entre treino e teste, o modelo captura estruturas ideológicas fundamentais 
que transcendem a simples memorização de fontes.

Por outro lado, os experimentos no FlipBias revelaram as fronteiras da generalização \textit{cross-domain}\footnote{Cross-domain refere-se à capacidade de um modelo, treinado em um conjunto de dados específico, de atuar ou ser avaliado em um outro conjunto de dados com características diferentes}, 
indicando que particularidades editoriais ainda influenciam os resultados em cenários sem ajuste fino. 
Para mitigar essa disparidade, trabalhos futuros focarão em técnicas de \textit{Domain Adaptation}. Além disso, planeja-se expandir 
os modelos para análises multilíngues e testar outros mecanismo utilizando modelos de linguagem de larga escala.




\bibliographystyle{sbc}
\bibliography{sbc-template}


\end{document}
