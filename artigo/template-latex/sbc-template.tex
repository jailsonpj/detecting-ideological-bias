\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}

\sloppy

\title{Instructions for Authors of SBC Conferences\\ Papers and Abstracts}

\author{Luciana P. Nedel\inst{1}, Rafael H. Bordini\inst{2}, Flávio Rech
  Wagner\inst{1}, Jomi F. Hübner\inst{3} }


\address{Instituto de Informática -- Universidade Federal do Rio Grande do Sul
  (UFRGS)\\
  Caixa Postal 15.064 -- 91.501-970 -- Porto Alegre -- RS -- Brazil
\nextinstitute
  Department of Computer Science -- University of Durham\\
  Durham, U.K.
\nextinstitute
  Departamento de Sistemas e Computação\\
  Universidade Regional de Blumenal (FURB) -- Blumenau, SC -- Brazil
  \email{\{nedel,flavio\}@inf.ufrgs.br, R.Bordini@durham.ac.uk,
  jomi@inf.furb.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This meta-paper describes the style to be used in articles and short papers
  for SBC conferences. For papers in English, you should add just an abstract
  while for the papers in Portuguese, we also ask for an abstract in
  Portuguese (``resumo''). In both cases, abstracts should not have more than
  10 lines and must be in the first page of the paper.
\end{abstract}
     
\begin{resumo} 
  Este meta-artigo descreve o estilo a ser usado na confecção de artigos e
  resumos de artigos para publicação nos anais das conferências organizadas
  pela SBC. É solicitada a escrita de resumo e abstract apenas para os artigos
  escritos em português. Artigos em inglês deverão apresentar apenas abstract.
  Nos dois casos, o autor deve tomar cuidado para que o resumo (e o abstract)
  não ultrapassem 10 linhas cada, sendo que ambos devem estar na primeira
  página do artigo.
\end{resumo}


\section{Introdução}\label{sec:intro}

\section{Trabalhos Relacionados}\label{sec:trabalhos}

\section{Material e Métodos}\label{sec:material}
A metodologia fundamenta-se na premissa de que o viés ideológico se manifesta
em padrões discursivos e semântico recorrentes. A abordagem proposta processa o
conteúdo textual de notícias utilizando modelos pré-treinados para a geração de
\textit{embeddings}, os quais são otimizados via \textit{fine-tuning} com as funções
de perda \textit{Contrastive Loss} e \textit{Triplet Loss}. Esse refinamento visa
maximizar orientações políticas, servindo como entrada para um classificador de
aprendizado de máquina.

Conforme ilustrado na Figura NUMERO, o fluxo de trabalho compreende quatro etapas principais:
\begin{itemize}
  \item \textbf{Aquisição de Dados}: Coleta baseada em conjunto de dados d literatura correlara;
  \item \textbf{Otimização de Representações}: Refinamento de \textit{embeddings} através de aprendizagem métrica (\textit{Contrastive} e \textit{Triplet Loss});
  \item \textbf{Treinamento}: Calibração do modelo de classificação sobre os vetores otimizados;
  \item \textbf{Avaliação}: análise do desempenho do sistema e dos resultados obtidos.
\end{itemize}
\subsection{Dados Experimentais}\label{sec:dados}

\subsection{Tarefa de Extração de Representações}\label{sec:representacoes}
Para a tarefa, foram empregados dois modelos baseados em \textit{Bidirectional Encoder Representations from Transformers (BERT)} [Devli et al., 2018],
que se destacam pela capacidade de modelar dependências de longo alcance e capturar relações semânticas em 
diferentes níveis de um documento. Foram selecionados o DistilBERT e o DistilRoBERTa [Sanh, 2019], versões
destiladas e eficientes que preservam a robustez das arquiteturas originais (BERT e RoBERTa, respectivamente), mas 
com uma redução significativa no custo computacional e nos requisitos de me mória. Essa base estrutural
permite a geração de representações vetoriais mais precisas e ágeis para tarefas complexas de processamento
de linguagem natural [Gao et al., 2021].

O processo de ajuste fino (\textit{fine-tuning}) foi realizado por meio de aprendizagem métrica\footnote{Para uma revisão detalhada sobre \textit{deep metric learning}.}, 
utilizando as funções de perda \textit{Triplet Loss} e \textit{Contrastive Loss}. Essa abordagem foi fundamental para 
otimizar os modelos na geração de \textit{embeddings} que preservam as relações semânticas dos dados, garantindo que 
vetores de exemplos contextualmente semelhantes sejam posicionados de forma próxima no espaço de representação, 
enquanto exemplos distintos permanecem devidamente segregados.

Quanto ao processamento dos dados, cada texto foi processado pelo tokenizador específico do modelo e ajustado 
(via truncamento ou \textit{padding}) para o limite de $512$ tokens. Notadamente, as \textit{stopwords} foram mantidas, visto que a 
arquitetura BERT é capaz de extrair informações contextuais valiosas a partir delas. Para consolidar as informações, 
aplicou-se a técnica de \textit{Mean Pooling} sobre a dimensão dos tokens, convertendo a sequência processada em um vetor único 
que captura as características mais relevantes de cada entrada.

Por fim, os modelos foram treinados seguindo as partições do ABP, utilizando o otimizador Adam com uma taxa de 
aprendizado de $0.0001$ e \textit{batch size} de $16$. A configuração experimental definiu um limite de $100$ épocas, determinado 
de forma empírica para o algoritmo de \textit{backpropagation}. Para evitar o \textit{overfitting}, aplicou-se a técnica de \textit{Early Stopping} 
com paciência de $30$ ciclos, interrompendo o treinamento com base no desempenho da função de perda no conjunto de validação.
%\begin{table}[ht]
%\centering
%\caption{Variables to be considered on the evaluation of interaction
%  techniques}
%\label{tab:exTable1}
%\includegraphics[width=.7\textwidth]{table.jpg}
%\end{table}

\subsubsection{Mecanismos de Aproximação e Distanciamento}\label{sec:funcoes}


Nesta abordagem, os codificadores (DistilBERT e DistilRoBERTa) ajustam os pesos de suas camadas para otimizar a 
qualidade dos \textit{embeddings} via \textit{Contrastive Loss} e \textit{Triplet Loss}. 
O objetivo é o aprendizado de representações vetoriais onde instâncias semanticamente similares convirjam no espaço representação, 
enquanto exemplos dissimilaridades sejam repelidos.

A \textit{Contrastive Loss} é aplicada utilizando a distância Euclidiana sobre pares de exemplos, conforme definido na Equação 1:

\begin{equation}
L = \frac{1}{2} (1-y) D^2 + \frac{1}{2} y \{ \max(0, m - D) \}^2
\end{equation}

Onde $y$ representa o rótulo binário (0 para similar, 1 para dissimilar), $D$ denota a distância entre as representações e $m$ é a margem de separação. 

Complementarmente, a \textit{Triplet Loss} utiliza triplas compostas por uma âncora ($a$), um exemplo positivo ($p$) e um negativo ($n$). 
O objetivo, expresso na Equação 2, assegura que a distância entre a âncora e o positivo seja inferior à distância entre a âncora e o negativo por uma margem $m$:

\begin{equation}
L = \max(0, D(a, p) - D(a, n) + m)
\end{equation}

Para otimizar o aprendizado, empregou-se o \textit{mining} de negativos \textit{semi-hard}. Esses exemplos, 
que satisfazem a condição $D(a, p) < D(a, n) + m$, fornecem gradientes mais informativos e 
mitigam o \textit{overfitting} em comparação a negativos \textit{hard} [kertez,2021]. Esse processo 
refina a capacidade discriminatória do modelo, permitindo que os \textit{embeddings} 
capturem relações semânticas profundas, como a ideologia de uma notícia, independentemente da fonte de publicação.


\subsection{Tarefa de Classificação: Modelos e Parametrizaçao}\label{sec:classificacao}
Após o mapeamento dos \textit{embeddings}, onde a proximidade entre os veotres reflete a similaridade ideológica das notícias.
A classificação dos artigos foi realizada por meio de três algoritmos: \textit{K-Nearest Neighbors (KNN)}, \textit{K-Means} e
\textit{Multilayer Perceptron (MLP)}. O \textit{KNN} e o \textit{K-Means} foram utilizados para explorar a organização dos dados
por vizinhaça e agrupamento, respectivamente. Para o \textit{KNN}, aplicou-se um \textit{grid search} sistemático para otimização de hiperparâmetros, variando o número de vizinhos ($k$)
entre $5, 10, 15, 20, 25$ e $30$. Já o \textit{K-Means} foi configurado com o número de \textit{clusters} equivalente às classes
presentes no conjunto de dados ABP.

A rede \textit{MLP} foi estruturada com duas camadas densas (512 e 256 neurônios). Adotou-se a função de ativação \textit{ReLU}
para garantir um treinamento mais rápido e estável [REFERENCIA], enquanto a camada de saída utilizou a \textit{softmax} para a 
classificação final. O modelo otimizado com o algoritmo \textit{Adam} [REFERENCIA] e a função de perda
\textit{Categorical Cross-Entropy}, escolhas consolidadas na literatura para problemas multiclasse [REFERENCIA GOODFELLOW].

A confiabilidade do experimento foi assegurada pela validacruzada estritificada (5-fold). Esse procedimento garante que a proporção das classes
seja mantida em todas as etapas, evitando resultados enviesados e permitindo medir com precisão a capacidade do modelo em classificar novos dados [REFERENCIA]

\subsection{Avaliação de Desempenho}

O desempenho dos modelos de classificação propostos será avaliado quantitativamente através das métricas de Acurácia e \textit{Macro F1-score}. 
A escolha de tais métricas fundamenta-se na necessidade de uma análise robusta: enquanto a acurácia fornece uma medida geral da taxa de acerto do modelo (Equação \ref{eq:accuracy}), 
o \textit{Macro F1-score} permite uma avaliação criteriosa da capacidade preditiva em todas as classes, 
mitigando distorções causadas por eventuais desbalanceamentos no conjunto de dados (Equação \ref{eq:macrof1}).

As métricas são formalmente definidas como segue:

\begin{equation}\label{eq:accuracy}
\text{Acur\'{a}cia} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\begin{equation}\label{eq:macrof1}
\text{Macro } F1 = \frac{1}{N} \sum_{i=1}^{N} F1_i
\end{equation}

Onde o $F1$ de cada classe é a média harmônica entre a Precisão e a Revocação, definidas nas Equações \ref{eq:prec_rec} e \ref{eq:f1}:

\begin{equation}\label{eq:prec_rec}
\text{Precis\~{a}o} = \frac{TP}{TP + FP}, \quad \text{Revocaç\~{a}o} = \frac{TP}{TP + FN}
\end{equation}

\begin{equation}\label{eq:f1}
F1 = \frac{2 \times (\text{Precis\~{a}o} \times \text{Revocação})}{\text{Precis\~{a}o} + \text{Revocaç\~{a}o}}
\end{equation}

Neste contexto, $TP$, $TN$, $FP$ e $FN$ representam, respectivamente, os verdadeiros positivos, 
verdadeiros negativos, falsos positivos e falsos negativos. $N$ indica o número total de categorias ideológicas. 

A validação da hipótese de pesquisa --- de que o discurso textual reflete o viés ideológico --- dar-se-á 
mediante a obtenção de altos índices em ambas as métricas. 
Espera-se que valores elevados de \textit{Macro F1-score} confirmem que o modelo possui alta 
capacidade discriminatória entre as diferentes vertentes ideológicas, garantindo que o desempenho 
não seja fruto de uma tendência majoritária no conjunto de dados.

\section{Resultados e Discussão}

A linguagem Python, com as bibliotecas Numpy, Pandas, Scikit-Learn e PyTorch, foi a ferramenta primária 
para implementação e avaliação dos modelos. Os experimentos ocorreram em um servidor com processador 
Intel Xeon W-2235, 128 GB de RAM e GPU NVIDIA RTX 8000 (48 GB VRAM), visando a aceleração em hardware.
Para garantir a reprodutibilidade, o código-fonte, hiperparâmetros e scripts de pré-processamento estão 
disponíveis em: \url{https://github.com/jailsonpj/detecting-ideological-bias}.

\section{Considerações Finais}

\section{References}

Bibliographic references must be unambiguous and uniform.  We recommend giving
the author names references in brackets, e.g. \cite{knuth:84},
\cite{boulic:91}, and \cite{smith:99}.

The references must be listed using 12 point font size, with 6 points of space
before each reference. The first line of each reference should not be
indented, while the subsequent should be indented by 0.5 cm.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
